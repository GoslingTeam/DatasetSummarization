{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 aarzookuhar hotel-recommendation-dataset\n",
      "1 abdelrahman16 car-data\n",
      "2 abdelrhamanfakhry movies-data-for-ml-dl-recommendation-system\n",
      "3 abderrahimalakouche flight-delay-prediction\n",
      "4 abdullahkhanuet22 olx-cars-dataset\n",
      "5 abdullahorzan moodify-dataset\n",
      "6 abhishtagatya my-anime-list-2021\n",
      "7 abisheksudarshan topic-modeling-for-research-articles\n",
      "8 abrambeyer us-hospital-overall-star-ratings-20162020\n",
      "9 abuchionwuegbusi movie-recommendation\n",
      "10 adhamelkomy news-classification-and-analysis-using-nlp\n",
      "11 adinishad yts-movie-dataset\n",
      "12 adithyaawati apartments-for-rent-classified\n",
      "13 adityadesai13 used-car-dataset-ford-and-mercedes\n",
      "14 adityadeshpande23 amsterdam-airbnb\n",
      "15 adityaramachandran27 nasa-near-earth-objects-information\n",
      "16 aguado nyc-taxi-jan-aug-2022\n",
      "17 agungpambudi africa-soil-mapping-isdasoil-exploration\n",
      "18 ahmedaliraja customer-rating-data-by-amazon\n",
      "19 ahmedashrafahmed household-power-consumption\n",
      "20 ahmedshahriarsakib usa-real-estate-dataset\n",
      "21 ahmettezcantekin beginner-datasets\n",
      "22 ahsanaseer top-rated-tmdb-movies-10k\n",
      "23 ajaysh women-apparel-recommendation-engine-amazoncom\n",
      "24 akash14 house-price-dataset\n",
      "25 akhilups insurance-product-purchase-prediction\n",
      "26 akouaorsot empiricisms-thinkers\n",
      "27 akshayamali netflix-clustering-and-recommendation\n",
      "28 aleexharris bitcoin-network-on-chain-blockchain-data\n",
      "29 aleksandrglotov car-prices-poland\n",
      "30 alessiasimone lego-sets-and-price-1955-2023\n",
      "31 alexanderfrosati goodbooks-10k-updated\n",
      "32 allegray book-recommendation-system-dataset\n",
      "33 amanbarthwal imdb-movies-data\n",
      "34 amanverma1999 a-comprehensive-dataset-for-ddos-attack\n",
      "35 amariaziz tunisian-stock-market\n",
      "36 amirhoseinsedaghati the-weather-of-187-countries-in-2020\n",
      "37 amiroft tehran-renting\n",
      "38 amolbhone lead-score-case-study\n",
      "39 anandaramg apartment-cost-in-new-york-city\n",
      "40 anandpuntambekar loan-case-study\n",
      "41 anashamoutni optical-care-reimbursements-in-france-20092021\n",
      "42 andreagarritano wikipedia-article-networks\n",
      "43 aniketsharma00411 wikihow-features\n",
      "44 anmolkumar house-price-prediction-challenge\n",
      "45 annecool37 museum-data\n",
      "46 anthonytherrien 20000-coding-questions-solved-with-code-llama-70b\n",
      "47 anutural product-review-dataset\n",
      "48 apkaayush tmdb-10000-movies-dataset\n",
      "49 arashnic an-unbiased-sequential-recommendation-dataset\n",
      "50 arbazkhan971 the-great-indian-hiring-hackathon\n",
      "51 arianghasemi iran-phone-ads\n",
      "52 arindamsahoo social-media-users\n",
      "53 arkaradeniz linear-regression-example-dataset\n",
      "54 arpikr uci-drug\n",
      "55 arplusman papers-by-subject\n",
      "56 arunklenin ps4e4-ensemble-ancillary\n",
      "57 aryansakhala coffee-recommendation\n",
      "58 asaniczka 52000-animation-movie-details-dataset-2024\n",
      "59 asharalikamil regression-technique-eda\n",
      "60 ashishkumarsingh123 telecom-churn-dataset\n",
      "61 ashishvaya recommendation-engine\n",
      "62 aslanahmedov self-driving-carbehavioural-cloning\n",
      "63 astronautelvis anime-recommendation\n",
      "64 austcse embedded-smartphone-sensor-data\n",
      "65 BidecInnovations stock-price-and-news-realted-to-it\n",
      "66 CooperUnion anime-recommendations-database\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# import json\n",
    "import glob\n",
    "\n",
    "data_dir_name = \"Data\"\n",
    "\n",
    "for i, user_name in enumerate(os.listdir(data_dir_name)):\n",
    "    \n",
    "    dataset_name = os.listdir(os.path.join(data_dir_name, user_name))[0]\n",
    "    path = os.path.join(data_dir_name, user_name, dataset_name)\n",
    "\n",
    "    print(i, user_name, dataset_name)\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        \n",
    "        if filename.endswith('.json'):\n",
    "            \n",
    "            metadata_prompt = \"DATASET METADATA:\\n\\n\"\n",
    "\n",
    "            with open(os.path.join(path, filename)) as f:\n",
    "                metadata_prompt += f\"{f.read()}\\n\\n\"\n",
    "\n",
    "\n",
    "        if filename.endswith('.zip'):\n",
    "            \n",
    "            data_prompt = \"DATASET FILES CONTENTS:\\n\\n\"\n",
    "\n",
    "            extraction_dir_name = os.path.join(path, filename[:-4])\n",
    "            \n",
    "            if not os.path.exists(extraction_dir_name):\n",
    "                os.makedirs(extraction_dir_name)\n",
    "                with zipfile.ZipFile(os.path.join(path, filename), 'r') as zip_ref:\n",
    "                    zip_ref.extractall(extraction_dir_name)\n",
    "            \n",
    "            all_paths = glob.glob(extraction_dir_name + \"/**/*\", recursive=True)\n",
    "            file_paths = [path for path in all_paths if os.path.isfile(path)]\n",
    "\n",
    "            for data_filename in file_paths:\n",
    "\n",
    "                data_prompt += f\"{data_filename}\\n\"\n",
    "\n",
    "                # try:\n",
    "                # with open(os.path.join(extraction_dir_name, data_filename), 'rb') as f:\n",
    "                with open(data_filename, 'rb') as f:\n",
    "                    data_file_content = f.read(1024)\n",
    "                # except:\n",
    "                #     data_file_content = \"*N/A*\"\n",
    "\n",
    "                data_prompt += f\"{data_file_content}\\n\"\n",
    "\n",
    "    prompt = metadata_prompt + data_prompt + \"\\n\"\n",
    "    prompt += \"Use DATASET METADATA and DATASET FILES CONTENTS to compose a dataset summary that has ONLY the following sections:\\n\"\n",
    "    prompt += \"1) \\\"What this data is about\\\": a single paragraph that describes the data in general without details\\n\"\n",
    "    prompt += \"2) \\\"How this data could be used\\\": a short list of the potential uses of the data in general without details\\n\"\n",
    "    prompt += \"\\n\"\n",
    "\n",
    "    prompt_filename = dataset_name.replace(\"\\\\\", \"_\") + \".txt\" \n",
    "    with open(os.path.join('Prompts', prompt_filename), 'w') as f:\n",
    "        f.write(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data\\\\adithyaawati\\\\apartments-for-rent-classified\\\\apartments-for-rent-classified\\\\apartments_for_rent_classified_100K\\\\apartments_for_rent_classified_100K.csv', 'Data\\\\adithyaawati\\\\apartments-for-rent-classified\\\\apartments-for-rent-classified\\\\apartments_for_rent_classified_10K\\\\apartments_for_rent_classified_10K.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "directory = os.path.join(\"Data\", \"adithyaawati\", \"apartments-for-rent-classified\", \"apartments-for-rent-classified\")\n",
    "\n",
    "all_paths = glob.glob(directory + \"/**/*\", recursive=True)\n",
    "\n",
    "file_paths = [path for path in all_paths if os.path.isfile(path)]\n",
    "\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aarzookuhar/hotel-recommendation-dataset\n",
      "abdelrahman16/car-data\n",
      "abdelrhamanfakhry/movies-data-for-ml-dl-recommendation-system\n",
      "abderrahimalakouche/flight-delay-prediction\n",
      "abdullahkhanuet22/olx-cars-dataset\n",
      "abdullahorzan/moodify-dataset\n",
      "abhishtagatya/my-anime-list-2021\n",
      "abisheksudarshan/topic-modeling-for-research-articles\n",
      "abrambeyer/us-hospital-overall-star-ratings-20162020\n",
      "abuchionwuegbusi/movie-recommendation\n",
      "adhamelkomy/news-classification-and-analysis-using-nlp\n",
      "adinishad/yts-movie-dataset\n",
      "adithyaawati/apartments-for-rent-classified\n",
      "adityadesai13/used-car-dataset-ford-and-mercedes\n",
      "adityadeshpande23/amsterdam-airbnb\n",
      "adityaramachandran27/nasa-near-earth-objects-information\n",
      "aguado/nyc-taxi-jan-aug-2022\n",
      "agungpambudi/africa-soil-mapping-isdasoil-exploration\n",
      "ahmedaliraja/customer-rating-data-by-amazon\n",
      "ahmedashrafahmed/household-power-consumption\n",
      "ahmedshahriarsakib/usa-real-estate-dataset\n",
      "ahmettezcantekin/beginner-datasets\n",
      "ahsanaseer/top-rated-tmdb-movies-10k\n",
      "ajaysh/women-apparel-recommendation-engine-amazoncom\n",
      "akash14/house-price-dataset\n",
      "akhilups/insurance-product-purchase-prediction\n",
      "akouaorsot/empiricisms-thinkers\n",
      "akshayamali/netflix-clustering-and-recommendation\n",
      "aleexharris/bitcoin-network-on-chain-blockchain-data\n",
      "aleksandrglotov/car-prices-poland\n",
      "alessiasimone/lego-sets-and-price-1955-2023\n",
      "alexanderfrosati/goodbooks-10k-updated\n",
      "allegray/book-recommendation-system-dataset\n",
      "amanbarthwal/imdb-movies-data\n",
      "amanverma1999/a-comprehensive-dataset-for-ddos-attack\n",
      "amariaziz/tunisian-stock-market\n",
      "amirhoseinsedaghati/the-weather-of-187-countries-in-2020\n",
      "amiroft/tehran-renting\n",
      "amolbhone/lead-score-case-study\n",
      "anandaramg/apartment-cost-in-new-york-city\n",
      "anandpuntambekar/loan-case-study\n",
      "anashamoutni/optical-care-reimbursements-in-france-20092021\n",
      "andreagarritano/wikipedia-article-networks\n",
      "aniketsharma00411/wikihow-features\n",
      "anmolkumar/house-price-prediction-challenge\n",
      "annecool37/museum-data\n",
      "anthonytherrien/20000-coding-questions-solved-with-code-llama-70b\n",
      "anutural/product-review-dataset\n",
      "apkaayush/tmdb-10000-movies-dataset\n",
      "arashnic/an-unbiased-sequential-recommendation-dataset\n",
      "arbazkhan971/the-great-indian-hiring-hackathon\n",
      "arianghasemi/iran-phone-ads\n",
      "arindamsahoo/social-media-users\n",
      "arkaradeniz/linear-regression-example-dataset\n",
      "arpikr/uci-drug\n",
      "arplusman/papers-by-subject\n",
      "arunklenin/ps4e4-ensemble-ancillary\n",
      "aryansakhala/coffee-recommendation\n",
      "asaniczka/52000-animation-movie-details-dataset-2024\n",
      "asharalikamil/regression-technique-eda\n",
      "ashishkumarsingh123/telecom-churn-dataset\n",
      "ashishvaya/recommendation-engine\n",
      "aslanahmedov/self-driving-carbehavioural-cloning\n",
      "astronautelvis/anime-recommendation\n",
      "austcse/embedded-smartphone-sensor-data\n",
      "BidecInnovations/stock-price-and-news-realted-to-it\n",
      "CooperUnion/anime-recommendations-database\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with open('datasets_names_list.txt') as f:\n",
    "    for user_name in os.listdir('Data'):\n",
    "        dataset_name = os.listdir(os.path.join('Data', user_name))[0]\n",
    "        f.write(f\"{user_name}/{dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
